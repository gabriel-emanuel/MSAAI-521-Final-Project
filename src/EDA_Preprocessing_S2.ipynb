{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "5HvgkpBsYbsy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLGbYyRM9BIh",
        "outputId": "b55eba63-55a9-456c-8757-b9fd7cf42dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive and download data from EDA step 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# configure google drive folders from EDA_Preprocessing.ipynb S1 file\n",
        "GDIR_PROJECT = '/content/drive/MyDrive/AAI-521/Module7/TeamProject'\n",
        "GDIR_PROJECT_EDA = GDIR_PROJECT + '/EDA_PrePro'\n",
        "GDIR_PROJECT_EDA_S1 = GDIR_PROJECT_EDA + '/S1'\n",
        "GDIR_PROJECT_EDA_S1_VAL = GDIR_PROJECT_EDA_S1 + '/val'\n",
        "GDIR_PROJECT_EDA_S1_TRAIN = GDIR_PROJECT_EDA_S1 + '/train'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read train and val set metadata from S1\n",
        "metadata_df_train = pd.read_csv(GDIR_PROJECT_EDA_S1_TRAIN + '/metadata_train.csv')\n",
        "metadata_df_val = pd.read_csv(GDIR_PROJECT_EDA_S1_VAL + '/metadata_val.csv')\n"
      ],
      "metadata": {
        "id": "tLzq3Gs9_Cog"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8rpx5-Z10p-U",
        "outputId": "2d6b2408-e65b-44f4-92f8-9e45d779eeb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b64500a1-ddd4-4258-9861-af27708f8a4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b64500a1-ddd4-4258-9861-af27708f8a4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b64500a1-ddd4-4258-9861-af27708f8a4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b64500a1-ddd4-4258-9861-af27708f8a4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5806c05b-314f-4bc7-aed2-fb9d8b2a27c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5806c05b-314f-4bc7-aed2-fb9d8b2a27c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5806c05b-314f-4bc7-aed2-fb9d8b2a27c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata_df_train",
              "summary": "{\n  \"name\": \"metadata_df_train\",\n  \"rows\": 8864,\n  \"fields\": [\n    {\n      \"column\": \"lesion_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6324,\n        \"samples\": [\n          \"HAM_0001998\",\n          \"HAM_0005260\",\n          \"HAM_0005943\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8864,\n        \"samples\": [\n          \"ISIC_0025918\",\n          \"ISIC_0030640\",\n          \"ISIC_0028023\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"bkl\",\n          \"nv\",\n          \"bcc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"consensus\",\n          \"follow_up\",\n          \"histo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.218301085253405,\n        \"min\": 0.0,\n        \"max\": 85.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          80.0,\n          75.0,\n          50.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"male\",\n          \"female\",\n          \"unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"localization\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"lower extremity\",\n          \"neck\",\n          \"scalp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create new folder to save further preprocessed images\n",
        "GDIR_PROJECT_EDA_S2 = GDIR_PROJECT_EDA + '/S2'\n",
        "GDIR_PROJECT_EDA_S2_VAL = GDIR_PROJECT_EDA_S2 + '/val'\n",
        "GDIR_PROJECT_EDA_S2_TRAIN = GDIR_PROJECT_EDA_S2 + '/train'\n",
        "os.makedirs(GDIR_PROJECT_EDA_S2, exist_ok=True)\n",
        "os.makedirs(GDIR_PROJECT_EDA_S2_VAL, exist_ok=True)\n",
        "os.makedirs(GDIR_PROJECT_EDA_S2_TRAIN, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "d_-ViQor0lQK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESIZE IMAGES TO A FIXED TARGET SIZE**\n",
        "> Resize images to a smaller target shape, but first, perform a quick EDA on the shape of the training images <br>"
      ],
      "metadata": {
        "id": "JV7VY2yhXwNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA on TRINING IMAGE SHAPES\n",
        "shapes = []\n",
        "\n",
        "# get image shapes in train_ds\n",
        "shapes = []\n",
        "image_count =0\n",
        "for root, dirs, files in os.walk(GDIR_PROJECT_EDA_S1_TRAIN):\n",
        "  for filename in files:\n",
        "     if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "        image_path = os.path.join(root, filename)\n",
        "        # Process the image here\n",
        "        with Image.open(image_path) as img:\n",
        "              shapes.append(img.size)\n",
        "        #print(f\"Processing image: {image_path}\")\n",
        "        print(f\"Processing image {image_count}\", end='\\r')\n",
        "        image_count += 1\n",
        "\n",
        "print(f\"Total images: {len(shapes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3y-YzsNy1VY",
        "outputId": "041a35ad-0152-4683-b14a-19b02f869c71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 8864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show shape count/distribution\n",
        "shape_distribution = np.unique(shapes, return_counts=True)\n",
        "shape_distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enDroB6z6yPr",
        "outputId": "cc0c78d7-296a-4ee6-ba8e-1e079c70c373"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([450, 600]), array([8864, 8864]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> All images are of shape 450x600. Images will be resized to 192x256 to maintain aspect ratio"
      ],
      "metadata": {
        "id": "LseJ1dWbSwgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set common parameters\n",
        "TARGET_SIZE = (192,256) # in preparation for CNN, From EDA, size in S1 is (450,600)\n",
        "BATCH_SIZE = 32\n",
        "RANDOM_SEED = 42\n"
      ],
      "metadata": {
        "id": "lkBkSo5QX5Yr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to resize images in a directory to a specified size\n",
        "# and saves resulting images to a target directory\n",
        "def resize_images(source_dir, target_dir):\n",
        "\n",
        "  # generate resized image dataset using keras\n",
        "  images_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    source_dir,\n",
        "    seed=RANDOM_SEED,\n",
        "    image_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',\n",
        "    crop_to_aspect_ratio=False, # prevents cropping\n",
        "    # This approach will resize the images while preserving their aspect ratio,\n",
        "    # avoiding distortion or loss of important visual information1.\n",
        "    # For skin cancer images, maintaining the original proportions is crucial for accurate diagnosis and analysis.\n",
        "    interpolation=\"bilinear\" # smooth resizing\n",
        "  )\n",
        "\n",
        "  # create subdirectories in target directory for resized images\n",
        "  for dx_type in images_ds.class_names:\n",
        "    os.makedirs(target_dir+'/'+dx_type, exist_ok=True)\n",
        "\n",
        "  # save resized images from images_ds into their respective dx type\n",
        "  image_num = 0\n",
        "  for batch, labels in images_ds:\n",
        "    for i, img in enumerate(batch):\n",
        "        # Convert the tensor to a numpy array\n",
        "        img_array = (img.numpy()).astype('uint8')\n",
        "\n",
        "        # get dx type\n",
        "        dx_type = images_ds.class_names[np.argmax(labels[i])]\n",
        "\n",
        "        # Generate a filename\n",
        "        filename = f'image_{image_num}.jpg'\n",
        "\n",
        "        # log\n",
        "        #print(f'i:{i} IMAGE_NO:{image_num} LABEL:{dx_type} FILENAME:{filename}')\n",
        "\n",
        "        image_num += 1\n",
        "\n",
        "        # Save Path\n",
        "        save_dir = os.path.join(target_dir, dx_type)\n",
        "        filepath = os.path.join(save_dir, filename)\n",
        "\n",
        "        # remove file if it exists\n",
        "        if os.path.exists(filepath):\n",
        "          os.remove(filepath)\n",
        "\n",
        "        tf.keras.utils.save_img(\n",
        "            filepath,\n",
        "            img_array,\n",
        "            scale=False  # We've already scaled the image\n",
        "\n",
        "        )\n"
      ],
      "metadata": {
        "id": "l_FUto1gNIWK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize validation set\n",
        "resize_images(GDIR_PROJECT_EDA_S1_VAL, GDIR_PROJECT_EDA_S2_VAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDvoLOCZP93W",
        "outputId": "d84c8bd7-e246-4f59-cfb2-f798c8acb1e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1094 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many val images we have in each dx type folder\n",
        "# should be consistent with EDAPREPROP PART I\n",
        "for dx_type in metadata_df_val['dx'].unique():\n",
        "  print(dx_type, len(os.listdir(GDIR_PROJECT_EDA_S2_VAL+'/'+dx_type)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6M-oLmbag5y",
        "outputId": "3751e523-6177-4199-e770-888cc826a7a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nv 876\n",
            "mel 46\n",
            "df 8\n",
            "bcc 35\n",
            "bkl 86\n",
            "akiec 30\n",
            "vasc 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resize training set\n",
        "resize_images(GDIR_PROJECT_EDA_S1_TRAIN, GDIR_PROJECT_EDA_S2_TRAIN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgF-Z3vVQ61y",
        "outputId": "f6c5fb15-d861-4412-fb2e-31b30f22a87c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8864 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many val images we have in each dx type folder\n",
        "# should be consistent with EDAPREPROP PART I\n",
        "for dx_type in metadata_df_val['dx'].unique():\n",
        "  print(dx_type, len(os.listdir(GDIR_PROJECT_EDA_S2_TRAIN+'/'+dx_type)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td5nAZxiSILP",
        "outputId": "d217efaa-db82-4f56-f4e1-3a4422fa5e60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nv 5784\n",
            "mel 1065\n",
            "df 107\n",
            "bcc 479\n",
            "bkl 1003\n",
            "akiec 297\n",
            "vasc 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATE AUGMENTED IMAGES TO HANDLE CLASS IMBALANCE (PERFORMED ONLY ON TRAINING SET)**\n",
        "\n",
        "> In each 'dx' class, generate augmented images from the existing ones until the total number of images reaches a target number."
      ],
      "metadata": {
        "id": "D0hSDowtszpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function that generates augmented images\n",
        "def generate_augmented_images(source_dir, target_dir, target_count, target_class):\n",
        "\n",
        "  # source_dir: basis of generation of augmented images, must contain subdirectories with different classes\n",
        "  # target_dir: where all augmented images and base images are saved, a subdirectory will be created for the specified target_class\n",
        "  #\n",
        "  # target_count: required number of images per target_class\n",
        "  # target_class: Image Data Generator will only consider images from the specified target_class\n",
        "\n",
        "  # uses global BATCH_SIZE and TARGET_SIZE variables\n",
        "  print(\"TARGET_CLASS: \", target_class)\n",
        "  # initialize image data generator\n",
        "  # many of the the configuratios below are from (1)\n",
        "  datagen = ImageDataGenerator(\n",
        "    rotation_range = 25, # as per (1)\n",
        "    width_shift_range=0.15, # as per (1)\n",
        "    height_shift_range=0.15, # as per (1)\n",
        "    zoom_range=0.1, # arbitrarily chosen\n",
        "    shear_range=0.15, # (1)\n",
        "    horizontal_flip=True, #(1)\n",
        "    vertical_flip=True, #(1)\n",
        "    brightness_range=(0.9,1.5), #(1)\n",
        "    fill_mode='nearest') # keras default\n",
        "\n",
        "  print(\"\\tSOURCE DIR: \", source_dir)\n",
        "\n",
        "  print(\"\\tTARGET_COUNT: \", target_count)\n",
        "\n",
        "  # create target directory for this class\n",
        "  target_dir = os.path.join(target_dir, target_class)\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "  print(\"\\tTARGET DIR: \", target_dir)\n",
        "\n",
        "  # apply image data generator above on source_dir\n",
        "  aug_generator = datagen.flow_from_directory(\n",
        "    source_dir,\n",
        "    seed=RANDOM_SEED,\n",
        "    save_to_dir=target_dir,\n",
        "    save_format='jpg',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=[target_class])\n",
        "\n",
        "  # count number of batches needed to generate augmented images for this class\n",
        "  num_base_images = len(os.listdir(target_dir))\n",
        "  print(\"\\tNUM BASE IMAGES: \", num_base_images)\n",
        "\n",
        "  num_aug_images_wanted = target_count - num_base_images\n",
        "  if(num_aug_images_wanted < 0): num_aug_images_wanted = 0\n",
        "  print(\"\\tNUM AUG IMAGES NEEDED: \", num_aug_images_wanted)\n",
        "\n",
        "  num_batches = int(np.ceil(num_aug_images_wanted / BATCH_SIZE))\n",
        "  print(\"\\tNUM BATCHES: \", num_batches, \"\\n\")\n",
        "\n",
        "  # call generator enough number of times to generate/save desired number of images\n",
        "  for i in range(num_batches):\n",
        "    images, labels = next(aug_generator)\n",
        "\n",
        "  return\n",
        "\n",
        "# the max number of samples per dx type is\n",
        "TARGET_NUMSAMPLES_PER_CLASS = metadata_df_train.groupby('dx').size().max()\n",
        "TARGET_NUMSAMPLES_PER_CLASS\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igQJKxugJtdz",
        "outputId": "28331fa9-0ac9-4bc6-8e61-ccc010f630c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5784"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply above function on each class in train\n",
        "source_dir = GDIR_PROJECT_EDA_S2_TRAIN\n",
        "target_dir = GDIR_PROJECT_EDA_S2_TRAIN\n",
        "\n",
        "for dx_type in metadata_df_train['dx'].unique():\n",
        "  generate_augmented_images(source_dir, target_dir, target_count = TARGET_NUMSAMPLES_PER_CLASS, target_class = dx_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIsJdr-qbJIH",
        "outputId": "14131661-41c6-4231-db8c-a346d501abf2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET_CLASS:  bkl\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/bkl\n",
            "Found 1003 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  1003\n",
            "\tNUM AUG IMAGES NEEDED:  4781\n",
            "\tNUM BATCHES:  150 \n",
            "\n",
            "TARGET_CLASS:  nv\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/nv\n",
            "Found 5784 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  5784\n",
            "\tNUM AUG IMAGES NEEDED:  0\n",
            "\tNUM BATCHES:  0 \n",
            "\n",
            "TARGET_CLASS:  df\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/df\n",
            "Found 107 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  107\n",
            "\tNUM AUG IMAGES NEEDED:  5677\n",
            "\tNUM BATCHES:  178 \n",
            "\n",
            "TARGET_CLASS:  mel\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/mel\n",
            "Found 1065 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  1065\n",
            "\tNUM AUG IMAGES NEEDED:  4719\n",
            "\tNUM BATCHES:  148 \n",
            "\n",
            "TARGET_CLASS:  vasc\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/vasc\n",
            "Found 129 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  129\n",
            "\tNUM AUG IMAGES NEEDED:  5655\n",
            "\tNUM BATCHES:  177 \n",
            "\n",
            "TARGET_CLASS:  bcc\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/bcc\n",
            "Found 479 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  479\n",
            "\tNUM AUG IMAGES NEEDED:  5305\n",
            "\tNUM BATCHES:  166 \n",
            "\n",
            "TARGET_CLASS:  akiec\n",
            "\tSOURCE DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train\n",
            "\tTARGET_COUNT:  5784\n",
            "\tTARGET DIR:  /content/drive/MyDrive/AAI-521/Module7/TeamProject/EDA_PrePro/S2/train/akiec\n",
            "Found 297 images belonging to 1 classes.\n",
            "\tNUM BASE IMAGES:  297\n",
            "\tNUM AUG IMAGES NEEDED:  5487\n",
            "\tNUM BATCHES:  172 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many val images we have in each dx type folder\n",
        "# should be consistent with EDAPREPROP PART I\n",
        "for dx_type in metadata_df_train['dx'].unique():\n",
        "  print(dx_type, len(os.listdir(GDIR_PROJECT_EDA_S2_TRAIN+'/'+dx_type)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c52yAX6eyzb",
        "outputId": "8b122129-e30f-478c-e051-208871efe697"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bkl 5719\n",
            "nv 5784\n",
            "df 4879\n",
            "mel 5709\n",
            "vasc 4708\n",
            "bcc 5780\n",
            "akiec 5410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REFERENCES**\n",
        "[1] Kumar Lilhore, U., Simaiya, S., Sharma, Y.K. et al. A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization. Sci Rep 14, 4299 (2024). https://doi.org/10.1038/s41598-024-54212-8"
      ],
      "metadata": {
        "id": "iH998QJjv9ej"
      }
    }
  ]
}